{"ast":null,"code":"import _toConsumableArray from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _classCallCheck from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport { isArray, isString } from 'vega-util';\nimport { getTypedFieldDef, isFieldDef, vgField } from '../../channeldef';\nimport { duplicate, getFirstDefined, hash as _hash } from '../../util';\nimport { sortParams } from '../common';\nimport { DataFlowNode } from './dataflow';\n\nfunction getStackByFields(model) {\n  return model.stack.stackBy.reduce(function (fields, by) {\n    var fieldDef = by.fieldDef;\n\n    var _field = vgField(fieldDef);\n\n    if (_field) {\n      fields.push(_field);\n    }\n\n    return fields;\n  }, []);\n}\n\nfunction isValidAsArray(as) {\n  return isArray(as) && as.every(function (s) {\n    return isString(s);\n  }) && as.length > 1;\n}\n\nexport var StackNode =\n/*#__PURE__*/\nfunction (_DataFlowNode) {\n  _inherits(StackNode, _DataFlowNode);\n\n  function StackNode(parent, stack) {\n    var _this;\n\n    _classCallCheck(this, StackNode);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(StackNode).call(this, parent));\n    _this._stack = stack;\n    return _this;\n  }\n\n  _createClass(StackNode, [{\n    key: \"clone\",\n    value: function clone() {\n      return new StackNode(null, duplicate(this._stack));\n    }\n  }, {\n    key: \"addDimensions\",\n    value: function addDimensions(fields) {\n      var _this$_stack$facetby;\n\n      (_this$_stack$facetby = this._stack.facetby).push.apply(_this$_stack$facetby, _toConsumableArray(fields));\n    }\n  }, {\n    key: \"dependentFields\",\n    value: function dependentFields() {\n      var out = new Set();\n      out.add(this._stack.stackField);\n      this.getGroupbyFields().forEach(function (f) {\n        return out.add(f);\n      });\n\n      this._stack.facetby.forEach(function (f) {\n        return out.add(f);\n      });\n\n      this._stack.sort.field.forEach(function (f) {\n        return out.add(f);\n      });\n\n      return out;\n    }\n  }, {\n    key: \"producedFields\",\n    value: function producedFields() {\n      return new Set(this._stack.as);\n    }\n  }, {\n    key: \"hash\",\n    value: function hash() {\n      return \"Stack \".concat(_hash(this._stack));\n    }\n  }, {\n    key: \"getGroupbyFields\",\n    value: function getGroupbyFields() {\n      var _this$_stack = this._stack,\n          dimensionFieldDef = _this$_stack.dimensionFieldDef,\n          impute = _this$_stack.impute,\n          groupby = _this$_stack.groupby;\n\n      if (dimensionFieldDef) {\n        if (dimensionFieldDef.bin) {\n          if (impute) {\n            // For binned group by field with impute, we calculate bin_mid\n            // as we cannot impute two fields simultaneously\n            return [vgField(dimensionFieldDef, {\n              binSuffix: 'mid'\n            })];\n          }\n\n          return [// For binned group by field without impute, we need both bin (start) and bin_end\n          vgField(dimensionFieldDef, {}), vgField(dimensionFieldDef, {\n            binSuffix: 'end'\n          })];\n        }\n\n        return [vgField(dimensionFieldDef)];\n      }\n\n      return groupby !== null && groupby !== void 0 ? groupby : [];\n    }\n  }, {\n    key: \"assemble\",\n    value: function assemble() {\n      var transform = [];\n      var _this$_stack2 = this._stack,\n          facetby = _this$_stack2.facetby,\n          dimensionFieldDef = _this$_stack2.dimensionFieldDef,\n          field = _this$_stack2.stackField,\n          stackby = _this$_stack2.stackby,\n          sort = _this$_stack2.sort,\n          offset = _this$_stack2.offset,\n          impute = _this$_stack2.impute,\n          as = _this$_stack2.as; // Impute\n\n      if (impute && dimensionFieldDef) {\n        var _dimensionFieldDef$ba = dimensionFieldDef.band,\n            band = _dimensionFieldDef$ba === void 0 ? 0.5 : _dimensionFieldDef$ba,\n            bin = dimensionFieldDef.bin;\n\n        if (bin) {\n          // As we can only impute one field at a time, we need to calculate\n          // mid point for a binned field\n          transform.push({\n            type: 'formula',\n            expr: \"\".concat(band, \"*\") + vgField(dimensionFieldDef, {\n              expr: 'datum'\n            }) + \"+\".concat(1 - band, \"*\") + vgField(dimensionFieldDef, {\n              expr: 'datum',\n              binSuffix: 'end'\n            }),\n            as: vgField(dimensionFieldDef, {\n              binSuffix: 'mid',\n              forAs: true\n            })\n          });\n        }\n\n        transform.push({\n          type: 'impute',\n          field: field,\n          groupby: [].concat(_toConsumableArray(stackby), _toConsumableArray(facetby)),\n          key: vgField(dimensionFieldDef, {\n            binSuffix: 'mid'\n          }),\n          method: 'value',\n          value: 0\n        });\n      } // Stack\n\n\n      transform.push({\n        type: 'stack',\n        groupby: [].concat(_toConsumableArray(this.getGroupbyFields()), _toConsumableArray(facetby)),\n        field: field,\n        sort: sort,\n        as: as,\n        offset: offset\n      });\n      return transform;\n    }\n  }, {\n    key: \"stack\",\n    get: function get() {\n      return this._stack;\n    }\n  }], [{\n    key: \"makeFromTransform\",\n    value: function makeFromTransform(parent, stackTransform) {\n      var stack = stackTransform.stack,\n          groupby = stackTransform.groupby,\n          as = stackTransform.as,\n          _stackTransform$offse = stackTransform.offset,\n          offset = _stackTransform$offse === void 0 ? 'zero' : _stackTransform$offse;\n      var sortFields = [];\n      var sortOrder = [];\n\n      if (stackTransform.sort !== undefined) {\n        var _iteratorNormalCompletion = true;\n        var _didIteratorError = false;\n        var _iteratorError = undefined;\n\n        try {\n          for (var _iterator = stackTransform.sort[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n            var sortField = _step.value;\n            sortFields.push(sortField.field);\n            sortOrder.push(getFirstDefined(sortField.order, 'ascending'));\n          }\n        } catch (err) {\n          _didIteratorError = true;\n          _iteratorError = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion && _iterator.return != null) {\n              _iterator.return();\n            }\n          } finally {\n            if (_didIteratorError) {\n              throw _iteratorError;\n            }\n          }\n        }\n      }\n\n      var sort = {\n        field: sortFields,\n        order: sortOrder\n      };\n      var normalizedAs;\n\n      if (isValidAsArray(as)) {\n        normalizedAs = as;\n      } else if (isString(as)) {\n        normalizedAs = [as, as + '_end'];\n      } else {\n        normalizedAs = [stackTransform.stack + '_start', stackTransform.stack + '_end'];\n      }\n\n      return new StackNode(parent, {\n        stackField: stack,\n        groupby: groupby,\n        offset: offset,\n        sort: sort,\n        facetby: [],\n        as: normalizedAs\n      });\n    }\n  }, {\n    key: \"makeFromEncoding\",\n    value: function makeFromEncoding(parent, model) {\n      var stackProperties = model.stack;\n      var encoding = model.encoding;\n\n      if (!stackProperties) {\n        return null;\n      }\n\n      var dimensionFieldDef;\n\n      if (stackProperties.groupbyChannel) {\n        var cDef = encoding[stackProperties.groupbyChannel];\n        dimensionFieldDef = getTypedFieldDef(cDef); // Fair to cast as groupByChannel is always either x or y\n      }\n\n      var stackby = getStackByFields(model);\n      var orderDef = model.encoding.order;\n      var sort;\n\n      if (isArray(orderDef) || isFieldDef(orderDef)) {\n        sort = sortParams(orderDef);\n      } else {\n        // default = descending by stackFields\n        // FIXME is the default here correct for binned fields?\n        sort = stackby.reduce(function (s, field) {\n          s.field.push(field);\n          s.order.push('descending');\n          return s;\n        }, {\n          field: [],\n          order: []\n        });\n      }\n\n      return new StackNode(parent, {\n        dimensionFieldDef: dimensionFieldDef,\n        stackField: model.vgField(stackProperties.fieldChannel),\n        facetby: [],\n        stackby: stackby,\n        sort: sort,\n        offset: stackProperties.offset,\n        impute: stackProperties.impute,\n        as: [model.vgField(stackProperties.fieldChannel, {\n          suffix: 'start',\n          forAs: true\n        }), model.vgField(stackProperties.fieldChannel, {\n          suffix: 'end',\n          forAs: true\n        })]\n      });\n    }\n  }]);\n\n  return StackNode;\n}(DataFlowNode);","map":null,"metadata":{},"sourceType":"module"}