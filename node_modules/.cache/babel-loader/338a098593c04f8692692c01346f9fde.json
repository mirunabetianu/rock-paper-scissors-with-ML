{"ast":null,"code":"import _toConsumableArray from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _classCallCheck from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport { MAIN } from '../../data';\nimport { fieldIntersection, hash, hasIntersection, keys, some } from '../../util';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { ParseNode } from './formatparse';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nimport { FACET_SCALE_PREFIX } from './optimize';\nimport { BottomUpOptimizer, isDataSourceNode, TopDownOptimizer } from './optimizer';\nimport { StackNode } from './stack';\nimport { TimeUnitNode } from './timeunit';\nimport { WindowTransformNode } from './window';\nimport { IdentifierNode } from './identifier';\nimport { requiresSelectionId } from '../selection';\n/**\n * Move parse nodes up to forks.\n */\n\nexport var MoveParseUp =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer) {\n  _inherits(MoveParseUp, _BottomUpOptimizer);\n\n  function MoveParseUp() {\n    _classCallCheck(this, MoveParseUp);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(MoveParseUp).apply(this, arguments));\n  }\n\n  _createClass(MoveParseUp, [{\n    key: \"run\",\n    value: function run(node) {\n      var parent = node.parent; // Move parse up by merging or swapping.\n\n      if (node instanceof ParseNode) {\n        if (isDataSourceNode(parent)) {\n          return this.flags;\n        }\n\n        if (parent.numChildren() > 1) {\n          // Don't move parse further up but continue with parent.\n          this.setContinue();\n          return this.flags;\n        }\n\n        if (parent instanceof ParseNode) {\n          this.setMutated();\n          parent.merge(node);\n        } else {\n          // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n          if (fieldIntersection(parent.producedFields(), node.dependentFields())) {\n            this.setContinue();\n            return this.flags;\n          }\n\n          this.setMutated();\n          node.swapWithParent();\n        }\n      }\n\n      this.setContinue();\n      return this.flags;\n    }\n  }]);\n\n  return MoveParseUp;\n}(BottomUpOptimizer);\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\n\nexport var MergeIdenticalNodes =\n/*#__PURE__*/\nfunction (_TopDownOptimizer) {\n  _inherits(MergeIdenticalNodes, _TopDownOptimizer);\n\n  function MergeIdenticalNodes() {\n    _classCallCheck(this, MergeIdenticalNodes);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(MergeIdenticalNodes).apply(this, arguments));\n  }\n\n  _createClass(MergeIdenticalNodes, [{\n    key: \"mergeNodes\",\n    value: function mergeNodes(parent, nodes) {\n      var mergedNode = nodes.shift();\n      var _iteratorNormalCompletion = true;\n      var _didIteratorError = false;\n      var _iteratorError = undefined;\n\n      try {\n        for (var _iterator = nodes[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n          var node = _step.value;\n          parent.removeChild(node);\n          node.parent = mergedNode;\n          node.remove();\n        }\n      } catch (err) {\n        _didIteratorError = true;\n        _iteratorError = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion && _iterator.return != null) {\n            _iterator.return();\n          }\n        } finally {\n          if (_didIteratorError) {\n            throw _iteratorError;\n          }\n        }\n      }\n    }\n  }, {\n    key: \"run\",\n    value: function run(node) {\n      var hashes = node.children.map(function (x) {\n        return x.hash();\n      });\n      var buckets = {};\n\n      for (var i = 0; i < hashes.length; i++) {\n        if (buckets[hashes[i]] === undefined) {\n          buckets[hashes[i]] = [node.children[i]];\n        } else {\n          buckets[hashes[i]].push(node.children[i]);\n        }\n      }\n\n      var _iteratorNormalCompletion2 = true;\n      var _didIteratorError2 = false;\n      var _iteratorError2 = undefined;\n\n      try {\n        for (var _iterator2 = keys(buckets)[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {\n          var k = _step2.value;\n\n          if (buckets[k].length > 1) {\n            this.setMutated();\n            this.mergeNodes(node, buckets[k]);\n          }\n        }\n      } catch (err) {\n        _didIteratorError2 = true;\n        _iteratorError2 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n            _iterator2.return();\n          }\n        } finally {\n          if (_didIteratorError2) {\n            throw _iteratorError2;\n          }\n        }\n      }\n\n      var _iteratorNormalCompletion3 = true;\n      var _didIteratorError3 = false;\n      var _iteratorError3 = undefined;\n\n      try {\n        for (var _iterator3 = node.children[Symbol.iterator](), _step3; !(_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done); _iteratorNormalCompletion3 = true) {\n          var child = _step3.value;\n          this.run(child);\n        }\n      } catch (err) {\n        _didIteratorError3 = true;\n        _iteratorError3 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion3 && _iterator3.return != null) {\n            _iterator3.return();\n          }\n        } finally {\n          if (_didIteratorError3) {\n            throw _iteratorError3;\n          }\n        }\n      }\n\n      return this.mutatedFlag;\n    }\n  }]);\n\n  return MergeIdenticalNodes;\n}(TopDownOptimizer);\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\n\nexport var RemoveUnusedSubtrees =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer2) {\n  _inherits(RemoveUnusedSubtrees, _BottomUpOptimizer2);\n\n  function RemoveUnusedSubtrees() {\n    _classCallCheck(this, RemoveUnusedSubtrees);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(RemoveUnusedSubtrees).apply(this, arguments));\n  }\n\n  _createClass(RemoveUnusedSubtrees, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {\n        // no need to continue with parent because it is output node or will have children (there was a fork)\n        return this.flags;\n      } else {\n        this.setMutated();\n        node.remove();\n      }\n\n      return this.flags;\n    }\n  }]);\n\n  return RemoveUnusedSubtrees;\n}(BottomUpOptimizer);\n/**\n * Removes duplicate time unit nodes (as determined by the name of the\n * output field) that may be generated due to selections projected over\n * time units.\n *\n * TODO: Try to make this a top down optimizer that keeps only the first\n * insance of a time unit node.\n * TODO: Try to make a generic version of this that only keeps one node per hash.\n */\n\nexport var RemoveDuplicateTimeUnits =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer3) {\n  _inherits(RemoveDuplicateTimeUnits, _BottomUpOptimizer3);\n\n  function RemoveDuplicateTimeUnits() {\n    var _this;\n\n    _classCallCheck(this, RemoveDuplicateTimeUnits);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(RemoveDuplicateTimeUnits).apply(this, arguments));\n    _this.fields = new Set();\n    _this.prev = null;\n    return _this;\n  }\n\n  _createClass(RemoveDuplicateTimeUnits, [{\n    key: \"run\",\n    value: function run(node) {\n      this.setContinue();\n\n      if (node instanceof TimeUnitNode) {\n        var pfields = node.producedFields();\n\n        if (hasIntersection(pfields, this.fields)) {\n          this.setMutated();\n          this.prev.remove();\n        } else {\n          this.fields = new Set([].concat(_toConsumableArray(this.fields), _toConsumableArray(pfields)));\n        }\n\n        this.prev = node;\n      }\n\n      return this.flags;\n    }\n  }, {\n    key: \"reset\",\n    value: function reset() {\n      this.fields.clear();\n    }\n  }]);\n\n  return RemoveDuplicateTimeUnits;\n}(BottomUpOptimizer);\n/**\n * Merge adjacent time unit nodes.\n */\n\nexport var MergeTimeUnits =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer4) {\n  _inherits(MergeTimeUnits, _BottomUpOptimizer4);\n\n  function MergeTimeUnits() {\n    _classCallCheck(this, MergeTimeUnits);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(MergeTimeUnits).apply(this, arguments));\n  }\n\n  _createClass(MergeTimeUnits, [{\n    key: \"run\",\n    value: function run(node) {\n      this.setContinue();\n      var parent = node.parent;\n      var timeUnitChildren = parent.children.filter(function (x) {\n        return x instanceof TimeUnitNode;\n      });\n      var combination = timeUnitChildren.pop();\n      var _iteratorNormalCompletion4 = true;\n      var _didIteratorError4 = false;\n      var _iteratorError4 = undefined;\n\n      try {\n        for (var _iterator4 = timeUnitChildren[Symbol.iterator](), _step4; !(_iteratorNormalCompletion4 = (_step4 = _iterator4.next()).done); _iteratorNormalCompletion4 = true) {\n          var timeUnit = _step4.value;\n          this.setMutated();\n          combination.merge(timeUnit);\n        }\n      } catch (err) {\n        _didIteratorError4 = true;\n        _iteratorError4 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion4 && _iterator4.return != null) {\n            _iterator4.return();\n          }\n        } finally {\n          if (_didIteratorError4) {\n            throw _iteratorError4;\n          }\n        }\n      }\n\n      return this.flags;\n    }\n  }]);\n\n  return MergeTimeUnits;\n}(BottomUpOptimizer);\n/**\n * Clones the subtree and ignores output nodes except for the leaves, which are renamed.\n */\n\nfunction cloneSubtree(facet) {\n  function clone(node) {\n    if (!(node instanceof FacetNode)) {\n      var copy = node.clone();\n\n      if (copy instanceof OutputNode) {\n        var newName = FACET_SCALE_PREFIX + copy.getSource();\n        copy.setSource(newName);\n        facet.model.component.data.outputNodes[newName] = copy;\n      } else if (copy instanceof AggregateNode || copy instanceof StackNode || copy instanceof WindowTransformNode || copy instanceof JoinAggregateTransformNode) {\n        copy.addDimensions(facet.fields);\n      }\n\n      node.children.flatMap(clone).forEach(function (n) {\n        return n.parent = copy;\n      });\n      return [copy];\n    }\n\n    return node.children.flatMap(clone);\n  }\n\n  return clone;\n}\n/**\n * Move facet nodes down to the next fork or output node. Also pull the main output with the facet node.\n * After moving down the facet node, make a copy of the subtree and make it a child of the main output.\n */\n\n\nexport function moveFacetDown(node) {\n  if (node instanceof FacetNode) {\n    if (node.numChildren() === 1 && !(node.children[0] instanceof OutputNode)) {\n      // move down until we hit a fork or output node\n      var child = node.children[0];\n\n      if (child instanceof AggregateNode || child instanceof StackNode || child instanceof WindowTransformNode || child instanceof JoinAggregateTransformNode) {\n        child.addDimensions(node.fields);\n      }\n\n      child.swapWithParent();\n      moveFacetDown(node);\n    } else {\n      // move main to facet\n      var facetMain = node.model.component.data.main;\n      moveMainDownToFacet(facetMain); // replicate the subtree and place it before the facet's main node\n\n      var cloner = cloneSubtree(node);\n      var copy = node.children.map(cloner).flat();\n      var _iteratorNormalCompletion5 = true;\n      var _didIteratorError5 = false;\n      var _iteratorError5 = undefined;\n\n      try {\n        for (var _iterator5 = copy[Symbol.iterator](), _step5; !(_iteratorNormalCompletion5 = (_step5 = _iterator5.next()).done); _iteratorNormalCompletion5 = true) {\n          var c = _step5.value;\n          c.parent = facetMain;\n        }\n      } catch (err) {\n        _didIteratorError5 = true;\n        _iteratorError5 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion5 && _iterator5.return != null) {\n            _iterator5.return();\n          }\n        } finally {\n          if (_didIteratorError5) {\n            throw _iteratorError5;\n          }\n        }\n      }\n    }\n  } else {\n    node.children.map(moveFacetDown);\n  }\n}\n\nfunction moveMainDownToFacet(node) {\n  if (node instanceof OutputNode && node.type === MAIN) {\n    if (node.numChildren() === 1) {\n      var child = node.children[0];\n\n      if (!(child instanceof FacetNode)) {\n        child.swapWithParent();\n        moveMainDownToFacet(node);\n      }\n    }\n  }\n}\n/**\n * Remove output nodes that are not required. Starting from a root.\n */\n\n\nexport var RemoveUnnecessaryOutputNodes =\n/*#__PURE__*/\nfunction (_TopDownOptimizer2) {\n  _inherits(RemoveUnnecessaryOutputNodes, _TopDownOptimizer2);\n\n  function RemoveUnnecessaryOutputNodes() {\n    _classCallCheck(this, RemoveUnnecessaryOutputNodes);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(RemoveUnnecessaryOutputNodes).call(this));\n  }\n\n  _createClass(RemoveUnnecessaryOutputNodes, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof OutputNode && !node.isRequired()) {\n        this.setMutated();\n        node.remove();\n      }\n\n      var _iteratorNormalCompletion6 = true;\n      var _didIteratorError6 = false;\n      var _iteratorError6 = undefined;\n\n      try {\n        for (var _iterator6 = node.children[Symbol.iterator](), _step6; !(_iteratorNormalCompletion6 = (_step6 = _iterator6.next()).done); _iteratorNormalCompletion6 = true) {\n          var child = _step6.value;\n          this.run(child);\n        }\n      } catch (err) {\n        _didIteratorError6 = true;\n        _iteratorError6 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion6 && _iterator6.return != null) {\n            _iterator6.return();\n          }\n        } finally {\n          if (_didIteratorError6) {\n            throw _iteratorError6;\n          }\n        }\n      }\n\n      return this.mutatedFlag;\n    }\n  }]);\n\n  return RemoveUnnecessaryOutputNodes;\n}(TopDownOptimizer);\nexport var RemoveUnnecessaryIdentifierNodes =\n/*#__PURE__*/\nfunction (_TopDownOptimizer3) {\n  _inherits(RemoveUnnecessaryIdentifierNodes, _TopDownOptimizer3);\n\n  function RemoveUnnecessaryIdentifierNodes(model) {\n    var _this2;\n\n    _classCallCheck(this, RemoveUnnecessaryIdentifierNodes);\n\n    _this2 = _possibleConstructorReturn(this, _getPrototypeOf(RemoveUnnecessaryIdentifierNodes).call(this));\n    _this2.requiresSelectionId = model && requiresSelectionId(model);\n    return _this2;\n  }\n\n  _createClass(RemoveUnnecessaryIdentifierNodes, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof IdentifierNode) {\n        // Only preserve IdentifierNodes if we have default discrete selections\n        // in our model tree, and if the nodes come after tuple producing nodes.\n        if (!(this.requiresSelectionId && (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode))) {\n          this.setMutated();\n          node.remove();\n        }\n      }\n\n      var _iteratorNormalCompletion7 = true;\n      var _didIteratorError7 = false;\n      var _iteratorError7 = undefined;\n\n      try {\n        for (var _iterator7 = node.children[Symbol.iterator](), _step7; !(_iteratorNormalCompletion7 = (_step7 = _iterator7.next()).done); _iteratorNormalCompletion7 = true) {\n          var child = _step7.value;\n          this.run(child);\n        }\n      } catch (err) {\n        _didIteratorError7 = true;\n        _iteratorError7 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion7 && _iterator7.return != null) {\n            _iterator7.return();\n          }\n        } finally {\n          if (_didIteratorError7) {\n            throw _iteratorError7;\n          }\n        }\n      }\n\n      return this.mutatedFlag;\n    }\n  }]);\n\n  return RemoveUnnecessaryIdentifierNodes;\n}(TopDownOptimizer);\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\n\nexport var MergeParse =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer5) {\n  _inherits(MergeParse, _BottomUpOptimizer5);\n\n  function MergeParse() {\n    _classCallCheck(this, MergeParse);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(MergeParse).apply(this, arguments));\n  }\n\n  _createClass(MergeParse, [{\n    key: \"run\",\n    value: function run(node) {\n      var parent = node.parent;\n\n      var originalChildren = _toConsumableArray(parent.children);\n\n      var parseChildren = parent.children.filter(function (child) {\n        return child instanceof ParseNode;\n      });\n\n      if (parent.numChildren() > 1 && parseChildren.length >= 1) {\n        var commonParse = {};\n        var conflictingParse = new Set();\n        var _iteratorNormalCompletion8 = true;\n        var _didIteratorError8 = false;\n        var _iteratorError8 = undefined;\n\n        try {\n          for (var _iterator8 = parseChildren[Symbol.iterator](), _step8; !(_iteratorNormalCompletion8 = (_step8 = _iterator8.next()).done); _iteratorNormalCompletion8 = true) {\n            var parseNode = _step8.value;\n            var parse = parseNode.parse;\n            var _iteratorNormalCompletion12 = true;\n            var _didIteratorError12 = false;\n            var _iteratorError12 = undefined;\n\n            try {\n              for (var _iterator12 = keys(parse)[Symbol.iterator](), _step12; !(_iteratorNormalCompletion12 = (_step12 = _iterator12.next()).done); _iteratorNormalCompletion12 = true) {\n                var k = _step12.value;\n\n                if (!(k in commonParse)) {\n                  commonParse[k] = parse[k];\n                } else if (commonParse[k] !== parse[k]) {\n                  conflictingParse.add(k);\n                }\n              }\n            } catch (err) {\n              _didIteratorError12 = true;\n              _iteratorError12 = err;\n            } finally {\n              try {\n                if (!_iteratorNormalCompletion12 && _iterator12.return != null) {\n                  _iterator12.return();\n                }\n              } finally {\n                if (_didIteratorError12) {\n                  throw _iteratorError12;\n                }\n              }\n            }\n          }\n        } catch (err) {\n          _didIteratorError8 = true;\n          _iteratorError8 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion8 && _iterator8.return != null) {\n              _iterator8.return();\n            }\n          } finally {\n            if (_didIteratorError8) {\n              throw _iteratorError8;\n            }\n          }\n        }\n\n        var _iteratorNormalCompletion9 = true;\n        var _didIteratorError9 = false;\n        var _iteratorError9 = undefined;\n\n        try {\n          for (var _iterator9 = conflictingParse[Symbol.iterator](), _step9; !(_iteratorNormalCompletion9 = (_step9 = _iterator9.next()).done); _iteratorNormalCompletion9 = true) {\n            var field = _step9.value;\n            delete commonParse[field];\n          }\n        } catch (err) {\n          _didIteratorError9 = true;\n          _iteratorError9 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion9 && _iterator9.return != null) {\n              _iterator9.return();\n            }\n          } finally {\n            if (_didIteratorError9) {\n              throw _iteratorError9;\n            }\n          }\n        }\n\n        if (keys(commonParse).length !== 0) {\n          this.setMutated();\n          var mergedParseNode = new ParseNode(parent, commonParse);\n          var _iteratorNormalCompletion10 = true;\n          var _didIteratorError10 = false;\n          var _iteratorError10 = undefined;\n\n          try {\n            for (var _iterator10 = originalChildren[Symbol.iterator](), _step10; !(_iteratorNormalCompletion10 = (_step10 = _iterator10.next()).done); _iteratorNormalCompletion10 = true) {\n              var childNode = _step10.value;\n\n              if (childNode instanceof ParseNode) {\n                var _iteratorNormalCompletion11 = true;\n                var _didIteratorError11 = false;\n                var _iteratorError11 = undefined;\n\n                try {\n                  for (var _iterator11 = keys(commonParse)[Symbol.iterator](), _step11; !(_iteratorNormalCompletion11 = (_step11 = _iterator11.next()).done); _iteratorNormalCompletion11 = true) {\n                    var key = _step11.value;\n                    delete childNode.parse[key];\n                  }\n                } catch (err) {\n                  _didIteratorError11 = true;\n                  _iteratorError11 = err;\n                } finally {\n                  try {\n                    if (!_iteratorNormalCompletion11 && _iterator11.return != null) {\n                      _iterator11.return();\n                    }\n                  } finally {\n                    if (_didIteratorError11) {\n                      throw _iteratorError11;\n                    }\n                  }\n                }\n              }\n\n              parent.removeChild(childNode);\n              childNode.parent = mergedParseNode; // remove empty parse nodes\n\n              if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n                childNode.remove();\n              }\n            }\n          } catch (err) {\n            _didIteratorError10 = true;\n            _iteratorError10 = err;\n          } finally {\n            try {\n              if (!_iteratorNormalCompletion10 && _iterator10.return != null) {\n                _iterator10.return();\n              }\n            } finally {\n              if (_didIteratorError10) {\n                throw _iteratorError10;\n              }\n            }\n          }\n        }\n      }\n\n      this.setContinue();\n      return this.flags;\n    }\n  }]);\n\n  return MergeParse;\n}(BottomUpOptimizer);\nexport var MergeAggregates =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer6) {\n  _inherits(MergeAggregates, _BottomUpOptimizer6);\n\n  function MergeAggregates() {\n    _classCallCheck(this, MergeAggregates);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(MergeAggregates).apply(this, arguments));\n  }\n\n  _createClass(MergeAggregates, [{\n    key: \"run\",\n    value: function run(node) {\n      var parent = node.parent;\n      var aggChildren = parent.children.filter(function (child) {\n        return child instanceof AggregateNode;\n      }); // Object which we'll use to map the fields which an aggregate is grouped by to\n      // the set of aggregates with that grouping. This is useful as only aggregates\n      // with the same group by can be merged\n\n      var groupedAggregates = {}; // Build groupedAggregates\n\n      var _iteratorNormalCompletion13 = true;\n      var _didIteratorError13 = false;\n      var _iteratorError13 = undefined;\n\n      try {\n        for (var _iterator13 = aggChildren[Symbol.iterator](), _step13; !(_iteratorNormalCompletion13 = (_step13 = _iterator13.next()).done); _iteratorNormalCompletion13 = true) {\n          var agg = _step13.value;\n          var groupBys = hash(agg.groupBy);\n\n          if (!(groupBys in groupedAggregates)) {\n            groupedAggregates[groupBys] = [];\n          }\n\n          groupedAggregates[groupBys].push(agg);\n        } // Merge aggregateNodes with same key in groupedAggregates\n\n      } catch (err) {\n        _didIteratorError13 = true;\n        _iteratorError13 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion13 && _iterator13.return != null) {\n            _iterator13.return();\n          }\n        } finally {\n          if (_didIteratorError13) {\n            throw _iteratorError13;\n          }\n        }\n      }\n\n      var _iteratorNormalCompletion14 = true;\n      var _didIteratorError14 = false;\n      var _iteratorError14 = undefined;\n\n      try {\n        for (var _iterator14 = keys(groupedAggregates)[Symbol.iterator](), _step14; !(_iteratorNormalCompletion14 = (_step14 = _iterator14.next()).done); _iteratorNormalCompletion14 = true) {\n          var group = _step14.value;\n          var mergeableAggs = groupedAggregates[group];\n\n          if (mergeableAggs.length > 1) {\n            var mergedAggs = mergeableAggs.pop();\n            var _iteratorNormalCompletion15 = true;\n            var _didIteratorError15 = false;\n            var _iteratorError15 = undefined;\n\n            try {\n              for (var _iterator15 = mergeableAggs[Symbol.iterator](), _step15; !(_iteratorNormalCompletion15 = (_step15 = _iterator15.next()).done); _iteratorNormalCompletion15 = true) {\n                var _agg = _step15.value;\n\n                if (mergedAggs.merge(_agg)) {\n                  parent.removeChild(_agg);\n                  _agg.parent = mergedAggs;\n\n                  _agg.remove();\n\n                  this.setMutated();\n                }\n              }\n            } catch (err) {\n              _didIteratorError15 = true;\n              _iteratorError15 = err;\n            } finally {\n              try {\n                if (!_iteratorNormalCompletion15 && _iterator15.return != null) {\n                  _iterator15.return();\n                }\n              } finally {\n                if (_didIteratorError15) {\n                  throw _iteratorError15;\n                }\n              }\n            }\n          }\n        }\n      } catch (err) {\n        _didIteratorError14 = true;\n        _iteratorError14 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion14 && _iterator14.return != null) {\n            _iterator14.return();\n          }\n        } finally {\n          if (_didIteratorError14) {\n            throw _iteratorError14;\n          }\n        }\n      }\n\n      this.setContinue();\n      return this.flags;\n    }\n  }]);\n\n  return MergeAggregates;\n}(BottomUpOptimizer);\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\n\nexport var MergeBins =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer7) {\n  _inherits(MergeBins, _BottomUpOptimizer7);\n\n  function MergeBins(model) {\n    var _this3;\n\n    _classCallCheck(this, MergeBins);\n\n    _this3 = _possibleConstructorReturn(this, _getPrototypeOf(MergeBins).call(this));\n    _this3.model = model;\n    return _this3;\n  }\n\n  _createClass(MergeBins, [{\n    key: \"run\",\n    value: function run(node) {\n      var parent = node.parent;\n      var moveBinsUp = !(isDataSourceNode(parent) || parent instanceof FilterNode || parent instanceof ParseNode || parent instanceof IdentifierNode);\n      var promotableBins = [];\n      var remainingBins = [];\n      var _iteratorNormalCompletion16 = true;\n      var _didIteratorError16 = false;\n      var _iteratorError16 = undefined;\n\n      try {\n        for (var _iterator16 = parent.children[Symbol.iterator](), _step16; !(_iteratorNormalCompletion16 = (_step16 = _iterator16.next()).done); _iteratorNormalCompletion16 = true) {\n          var child = _step16.value;\n\n          if (child instanceof BinNode) {\n            if (moveBinsUp && !fieldIntersection(parent.producedFields(), child.dependentFields())) {\n              promotableBins.push(child);\n            } else {\n              remainingBins.push(child);\n            }\n          }\n        }\n      } catch (err) {\n        _didIteratorError16 = true;\n        _iteratorError16 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion16 && _iterator16.return != null) {\n            _iterator16.return();\n          }\n        } finally {\n          if (_didIteratorError16) {\n            throw _iteratorError16;\n          }\n        }\n      }\n\n      if (promotableBins.length > 0) {\n        var promotedBin = promotableBins.pop();\n        var _iteratorNormalCompletion17 = true;\n        var _didIteratorError17 = false;\n        var _iteratorError17 = undefined;\n\n        try {\n          for (var _iterator17 = promotableBins[Symbol.iterator](), _step17; !(_iteratorNormalCompletion17 = (_step17 = _iterator17.next()).done); _iteratorNormalCompletion17 = true) {\n            var bin = _step17.value;\n            promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n          }\n        } catch (err) {\n          _didIteratorError17 = true;\n          _iteratorError17 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion17 && _iterator17.return != null) {\n              _iterator17.return();\n            }\n          } finally {\n            if (_didIteratorError17) {\n              throw _iteratorError17;\n            }\n          }\n        }\n\n        this.setMutated();\n\n        if (parent instanceof BinNode) {\n          parent.merge(promotedBin, this.model.renameSignal.bind(this.model));\n        } else {\n          promotedBin.swapWithParent();\n        }\n      }\n\n      if (remainingBins.length > 1) {\n        var remainingBin = remainingBins.pop();\n        var _iteratorNormalCompletion18 = true;\n        var _didIteratorError18 = false;\n        var _iteratorError18 = undefined;\n\n        try {\n          for (var _iterator18 = remainingBins[Symbol.iterator](), _step18; !(_iteratorNormalCompletion18 = (_step18 = _iterator18.next()).done); _iteratorNormalCompletion18 = true) {\n            var _bin = _step18.value;\n            remainingBin.merge(_bin, this.model.renameSignal.bind(this.model));\n          }\n        } catch (err) {\n          _didIteratorError18 = true;\n          _iteratorError18 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion18 && _iterator18.return != null) {\n              _iterator18.return();\n            }\n          } finally {\n            if (_didIteratorError18) {\n              throw _iteratorError18;\n            }\n          }\n        }\n\n        this.setMutated();\n      }\n\n      this.setContinue();\n      return this.flags;\n    }\n  }]);\n\n  return MergeBins;\n}(BottomUpOptimizer);\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a cahin of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\n\nexport var MergeOutputs =\n/*#__PURE__*/\nfunction (_BottomUpOptimizer8) {\n  _inherits(MergeOutputs, _BottomUpOptimizer8);\n\n  function MergeOutputs() {\n    _classCallCheck(this, MergeOutputs);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(MergeOutputs).apply(this, arguments));\n  }\n\n  _createClass(MergeOutputs, [{\n    key: \"run\",\n    value: function run(node) {\n      var parent = node.parent;\n\n      var children = _toConsumableArray(parent.children);\n\n      var hasOutputChild = some(children, function (child) {\n        return child instanceof OutputNode;\n      });\n\n      if (!hasOutputChild || parent.numChildren() <= 1) {\n        this.setContinue();\n        return this.flags;\n      }\n\n      var otherChildren = []; // The output node we will connect all other nodes to\n      // output nodes will be added before, other nodes after\n\n      var mainOutput;\n      var _iteratorNormalCompletion19 = true;\n      var _didIteratorError19 = false;\n      var _iteratorError19 = undefined;\n\n      try {\n        for (var _iterator19 = children[Symbol.iterator](), _step19; !(_iteratorNormalCompletion19 = (_step19 = _iterator19.next()).done); _iteratorNormalCompletion19 = true) {\n          var _child = _step19.value;\n\n          if (_child instanceof OutputNode) {\n            var lastOutput = _child;\n\n            while (lastOutput.numChildren() === 1) {\n              var theChild = lastOutput.children[0];\n\n              if (theChild instanceof OutputNode) {\n                lastOutput = theChild;\n              } else {\n                break;\n              }\n            }\n\n            otherChildren.push.apply(otherChildren, _toConsumableArray(lastOutput.children));\n\n            if (mainOutput) {\n              // Move the output nodes before the mainOutput. We do this by setting\n              // the parent of the first not to the parent of the main output and\n              // the main output's parent to the last output.\n              // note: the child is the first output\n              parent.removeChild(_child);\n              _child.parent = mainOutput.parent;\n              mainOutput.parent.removeChild(mainOutput);\n              mainOutput.parent = lastOutput;\n              this.setMutated();\n            } else {\n              mainOutput = lastOutput;\n            }\n          } else {\n            otherChildren.push(_child);\n          }\n        }\n      } catch (err) {\n        _didIteratorError19 = true;\n        _iteratorError19 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion19 && _iterator19.return != null) {\n            _iterator19.return();\n          }\n        } finally {\n          if (_didIteratorError19) {\n            throw _iteratorError19;\n          }\n        }\n      }\n\n      if (otherChildren.length) {\n        this.setMutated();\n        var _iteratorNormalCompletion20 = true;\n        var _didIteratorError20 = false;\n        var _iteratorError20 = undefined;\n\n        try {\n          for (var _iterator20 = otherChildren[Symbol.iterator](), _step20; !(_iteratorNormalCompletion20 = (_step20 = _iterator20.next()).done); _iteratorNormalCompletion20 = true) {\n            var child = _step20.value;\n            child.parent.removeChild(child);\n            child.parent = mainOutput;\n          }\n        } catch (err) {\n          _didIteratorError20 = true;\n          _iteratorError20 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion20 && _iterator20.return != null) {\n              _iterator20.return();\n            }\n          } finally {\n            if (_didIteratorError20) {\n              throw _iteratorError20;\n            }\n          }\n        }\n      }\n\n      this.setContinue();\n      return this.flags;\n    }\n  }]);\n\n  return MergeOutputs;\n}(BottomUpOptimizer);","map":null,"metadata":{},"sourceType":"module"}