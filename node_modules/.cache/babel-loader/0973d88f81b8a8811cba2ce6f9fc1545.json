{"ast":null,"code":"import _defineProperty from \"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/esm/defineProperty\";\nimport { isGenerator, isGraticuleGenerator, isInlineData, isNamedData, isSequenceGenerator, isUrlData, MAIN, RAW } from '../../data';\nimport * as log from '../../log';\nimport { isAggregate, isBin, isCalculate, isDensity, isFilter, isFlatten, isFold, isImpute, isJoinAggregate, isLoess, isLookup, isPivot, isQuantile, isRegression, isSample, isStack, isTimeUnit, isWindow } from '../../transform';\nimport { deepEqual, mergeDeep } from '../../util';\nimport { isFacetModel, isLayerModel, isUnitModel } from '../model';\nimport { requiresSelectionId } from '../selection';\nimport { materializeSelections } from '../selection/parse';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { CalculateNode } from './calculate';\nimport { OutputNode } from './dataflow';\nimport { DensityTransformNode } from './density';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { FilterInvalidNode } from './filterinvalid';\nimport { FlattenTransformNode } from './flatten';\nimport { FoldTransformNode } from './fold';\nimport { getImplicitFromEncoding, getImplicitFromFilterTransform, getImplicitFromSelection, ParseNode } from './formatparse';\nimport { GeoJSONNode } from './geojson';\nimport { GeoPointNode } from './geopoint';\nimport { GraticuleNode } from './graticule';\nimport { IdentifierNode } from './identifier';\nimport { ImputeNode } from './impute';\nimport { AncestorParse } from '.';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nimport { makeJoinAggregateFromFacet } from './joinaggregatefacet';\nimport { LoessTransformNode } from './loess';\nimport { LookupNode } from './lookup';\nimport { PivotTransformNode } from './pivot';\nimport { QuantileTransformNode } from './quantile';\nimport { RegressionTransformNode } from './regression';\nimport { SampleTransformNode } from './sample';\nimport { SequenceNode } from './sequence';\nimport { SourceNode } from './source';\nimport { StackNode } from './stack';\nimport { TimeUnitNode } from './timeunit';\nimport { WindowTransformNode } from './window';\nexport function findSource(data, sources) {\n  var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k;\n\n  var _iteratorNormalCompletion = true;\n  var _didIteratorError = false;\n  var _iteratorError = undefined;\n\n  try {\n    for (var _iterator = sources[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n      var other = _step.value;\n      var otherData = other.data; // if both datasets have a name defined, we cannot merge\n\n      if (data.name && other.hasName() && data.name !== other.dataName) {\n        continue;\n      } // feature and mesh are mutually exclusive\n\n\n      if (((_a = data['format']) === null || _a === void 0 ? void 0 : _a.mesh) && ((_b = otherData.format) === null || _b === void 0 ? void 0 : _b.feature)) {\n        continue;\n      } // we have to extract the same feature or mesh\n\n\n      if ((((_c = data['format']) === null || _c === void 0 ? void 0 : _c.feature) || ((_d = otherData.format) === null || _d === void 0 ? void 0 : _d.feature)) && ((_e = data['format']) === null || _e === void 0 ? void 0 : _e.feature) !== ((_f = otherData.format) === null || _f === void 0 ? void 0 : _f.feature)) {\n        continue;\n      }\n\n      if ((((_g = data['format']) === null || _g === void 0 ? void 0 : _g.mesh) || ((_h = otherData.format) === null || _h === void 0 ? void 0 : _h.mesh)) && ((_j = data['format']) === null || _j === void 0 ? void 0 : _j.mesh) !== ((_k = otherData.format) === null || _k === void 0 ? void 0 : _k.mesh)) {\n        continue;\n      }\n\n      if (isInlineData(data) && isInlineData(otherData)) {\n        if (deepEqual(data.values, otherData.values)) {\n          return other;\n        }\n      } else if (isUrlData(data) && isUrlData(otherData)) {\n        if (data.url === otherData.url) {\n          return other;\n        }\n      } else if (isNamedData(data)) {\n        if (data.name === other.dataName) {\n          return other;\n        }\n      }\n    }\n  } catch (err) {\n    _didIteratorError = true;\n    _iteratorError = err;\n  } finally {\n    try {\n      if (!_iteratorNormalCompletion && _iterator.return != null) {\n        _iterator.return();\n      }\n    } finally {\n      if (_didIteratorError) {\n        throw _iteratorError;\n      }\n    }\n  }\n\n  return null;\n}\n\nfunction parseRoot(model, sources) {\n  if (model.data || !model.parent) {\n    // if the model defines a data source or is the root, create a source node\n    if (model.data === null) {\n      // data: null means we should ignore the parent's data so we just create a new data source\n      var source = new SourceNode([]);\n      sources.push(source);\n      return source;\n    }\n\n    var existingSource = findSource(model.data, sources);\n\n    if (existingSource) {\n      if (!isGenerator(model.data)) {\n        existingSource.data.format = mergeDeep({}, model.data.format, existingSource.data.format);\n      } // if the new source has a name but the existing one does not, we can set it\n\n\n      if (!existingSource.hasName() && model.data.name) {\n        existingSource.dataName = model.data.name;\n      }\n\n      return existingSource;\n    } else {\n      var _source = new SourceNode(model.data);\n\n      sources.push(_source);\n      return _source;\n    }\n  } else {\n    // If we don't have a source defined (overriding parent's data), use the parent's facet root or main.\n    return model.parent.component.data.facetRoot ? model.parent.component.data.facetRoot : model.parent.component.data.main;\n  }\n}\n/**\n * Parses a transform array into a chain of connected dataflow nodes.\n */\n\n\nexport function parseTransformArray(head, model, ancestorParse) {\n  var _a, _b;\n\n  var lookupCounter = 0;\n  var _iteratorNormalCompletion2 = true;\n  var _didIteratorError2 = false;\n  var _iteratorError2 = undefined;\n\n  try {\n    for (var _iterator2 = model.transforms[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {\n      var t = _step2.value;\n      var derivedType = undefined;\n      var transformNode = void 0;\n\n      if (isCalculate(t)) {\n        transformNode = head = new CalculateNode(head, t);\n        derivedType = 'derived';\n      } else if (isFilter(t)) {\n        var implicit = getImplicitFromFilterTransform(t);\n        transformNode = head = (_a = ParseNode.makeWithAncestors(head, {}, implicit, ancestorParse), _a !== null && _a !== void 0 ? _a : head);\n        head = new FilterNode(head, model, t.filter);\n      } else if (isBin(t)) {\n        transformNode = head = BinNode.makeFromTransform(head, t, model);\n        derivedType = 'number';\n      } else if (isTimeUnit(t)) {\n        derivedType = 'date';\n        var parsedAs = ancestorParse.getWithExplicit(t.field); // Create parse node because the input to time unit is always date.\n\n        if (parsedAs.value === undefined) {\n          head = new ParseNode(head, _defineProperty({}, t.field, derivedType));\n          ancestorParse.set(t.field, derivedType, false);\n        }\n\n        transformNode = head = TimeUnitNode.makeFromTransform(head, t);\n      } else if (isAggregate(t)) {\n        transformNode = head = AggregateNode.makeFromTransform(head, t);\n        derivedType = 'number';\n\n        if (requiresSelectionId(model)) {\n          head = new IdentifierNode(head);\n        }\n      } else if (isLookup(t)) {\n        transformNode = head = LookupNode.make(head, model, t, lookupCounter++);\n        derivedType = 'derived';\n      } else if (isWindow(t)) {\n        transformNode = head = new WindowTransformNode(head, t);\n        derivedType = 'number';\n      } else if (isJoinAggregate(t)) {\n        transformNode = head = new JoinAggregateTransformNode(head, t);\n        derivedType = 'number';\n      } else if (isStack(t)) {\n        transformNode = head = StackNode.makeFromTransform(head, t);\n        derivedType = 'derived';\n      } else if (isFold(t)) {\n        transformNode = head = new FoldTransformNode(head, t);\n        derivedType = 'derived';\n      } else if (isFlatten(t)) {\n        transformNode = head = new FlattenTransformNode(head, t);\n        derivedType = 'derived';\n      } else if (isPivot(t)) {\n        transformNode = head = new PivotTransformNode(head, t);\n        derivedType = 'derived';\n      } else if (isSample(t)) {\n        head = new SampleTransformNode(head, t);\n      } else if (isImpute(t)) {\n        transformNode = head = ImputeNode.makeFromTransform(head, t);\n        derivedType = 'derived';\n      } else if (isDensity(t)) {\n        transformNode = head = new DensityTransformNode(head, t);\n        derivedType = 'derived';\n      } else if (isQuantile(t)) {\n        transformNode = head = new QuantileTransformNode(head, t);\n        derivedType = 'derived';\n      } else if (isRegression(t)) {\n        transformNode = head = new RegressionTransformNode(head, t);\n        derivedType = 'derived';\n      } else if (isLoess(t)) {\n        transformNode = head = new LoessTransformNode(head, t);\n        derivedType = 'derived';\n      } else {\n        log.warn(log.message.invalidTransformIgnored(t));\n        continue;\n      }\n\n      if (transformNode && derivedType !== undefined) {\n        var _iteratorNormalCompletion3 = true;\n        var _didIteratorError3 = false;\n        var _iteratorError3 = undefined;\n\n        try {\n          for (var _iterator3 = (_b = transformNode.producedFields(), _b !== null && _b !== void 0 ? _b : [])[Symbol.iterator](), _step3; !(_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done); _iteratorNormalCompletion3 = true) {\n            var field = _step3.value;\n            ancestorParse.set(field, derivedType, false);\n          }\n        } catch (err) {\n          _didIteratorError3 = true;\n          _iteratorError3 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion3 && _iterator3.return != null) {\n              _iterator3.return();\n            }\n          } finally {\n            if (_didIteratorError3) {\n              throw _iteratorError3;\n            }\n          }\n        }\n      }\n    }\n  } catch (err) {\n    _didIteratorError2 = true;\n    _iteratorError2 = err;\n  } finally {\n    try {\n      if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n        _iterator2.return();\n      }\n    } finally {\n      if (_didIteratorError2) {\n        throw _iteratorError2;\n      }\n    }\n  }\n\n  return head;\n}\n/*\nDescription of the dataflow (http://asciiflow.com/):\n     +--------+\n     | Source |\n     +---+----+\n         |\n         v\n     FormatParse\n     (explicit)\n         |\n         v\n     Transforms\n(Filter, Calculate, Binning, TimeUnit, Aggregate, Window, ...)\n         |\n         v\n     FormatParse\n     (implicit)\n         |\n         v\n Binning (in `encoding`)\n         |\n         v\n Timeunit (in `encoding`)\n         |\n         v\nFormula From Sort Array\n         |\n         v\n      +--+--+\n      | Raw |\n      +-----+\n         |\n         v\n  Aggregate (in `encoding`)\n         |\n         v\n  Stack (in `encoding`)\n         |\n         v\n  Invalid Filter\n         |\n         v\n   +----------+\n   |   Main   |\n   +----------+\n         |\n         v\n     +-------+\n     | Facet |----> \"column\", \"column-layout\", and \"row\"\n     +-------+\n         |\n         v\n  ...Child data...\n*/\n\nexport function parseData(model) {\n  var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l;\n\n  var head = parseRoot(model, model.component.data.sources);\n  var _model$component$data = model.component.data,\n      outputNodes = _model$component$data.outputNodes,\n      outputNodeRefCounts = _model$component$data.outputNodeRefCounts;\n  var ancestorParse = model.parent ? model.parent.component.data.ancestorParse.clone() : new AncestorParse();\n  var data = model.data;\n\n  if (isGenerator(data)) {\n    // insert generator transform\n    if (isSequenceGenerator(data)) {\n      head = new SequenceNode(head, data.sequence);\n    } else if (isGraticuleGenerator(data)) {\n      head = new GraticuleNode(head, data.graticule);\n    } // no parsing necessary for generator\n\n\n    ancestorParse.parseNothing = true;\n  } else if (((_b = (_a = data) === null || _a === void 0 ? void 0 : _a.format) === null || _b === void 0 ? void 0 : _b.parse) === null) {\n    // format.parse: null means disable parsing\n    ancestorParse.parseNothing = true;\n  }\n\n  head = (_c = ParseNode.makeExplicit(head, model, ancestorParse), _c !== null && _c !== void 0 ? _c : head); // Default discrete selections require an identifer transform to\n  // uniquely identify data points. Add this transform at the head of\n  // the pipeline such that the identifier field is available for all\n  // subsequent datasets. During optimization, we will remove this\n  // transform if it proves to be unnecessary. Additional identifier\n  // transforms will be necessary when new tuples are constructed\n  // (e.g., post-aggregation).\n\n  head = new IdentifierNode(head); // HACK: This is equivalent for merging bin extent for union scale.\n  // FIXME(https://github.com/vega/vega-lite/issues/2270): Correctly merge extent / bin node for shared bin scale\n\n  var parentIsLayer = model.parent && isLayerModel(model.parent);\n\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (parentIsLayer) {\n      head = (_d = BinNode.makeFromEncoding(head, model), _d !== null && _d !== void 0 ? _d : head);\n    }\n  }\n\n  if (model.transforms.length > 0) {\n    head = parseTransformArray(head, model, ancestorParse);\n  } // create parse nodes for fields that need to be parsed (or flattened) implicitly\n\n\n  var implicitSelection = getImplicitFromSelection(model);\n  var implicitEncoding = getImplicitFromEncoding(model);\n  head = (_e = ParseNode.makeWithAncestors(head, {}, Object.assign(Object.assign({}, implicitSelection), implicitEncoding), ancestorParse), _e !== null && _e !== void 0 ? _e : head);\n\n  if (isUnitModel(model)) {\n    head = GeoJSONNode.parseAll(head, model);\n    head = GeoPointNode.parseAll(head, model);\n  }\n\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (!parentIsLayer) {\n      head = (_f = BinNode.makeFromEncoding(head, model), _f !== null && _f !== void 0 ? _f : head);\n    }\n\n    head = (_g = TimeUnitNode.makeFromEncoding(head, model), _g !== null && _g !== void 0 ? _g : head);\n    head = CalculateNode.parseAllForSortIndex(head, model);\n  } // add an output node pre aggregation\n\n\n  var rawName = model.getName(RAW);\n  var raw = new OutputNode(head, rawName, RAW, outputNodeRefCounts);\n  outputNodes[rawName] = raw;\n  head = raw;\n\n  if (isUnitModel(model)) {\n    var agg = AggregateNode.makeFromEncoding(head, model);\n\n    if (agg) {\n      head = agg;\n\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    }\n\n    head = (_h = ImputeNode.makeFromEncoding(head, model), _h !== null && _h !== void 0 ? _h : head);\n    head = (_j = StackNode.makeFromEncoding(head, model), _j !== null && _j !== void 0 ? _j : head);\n  }\n\n  if (isUnitModel(model)) {\n    head = (_k = FilterInvalidNode.make(head, model), _k !== null && _k !== void 0 ? _k : head);\n  } // output node for marks\n\n\n  var mainName = model.getName(MAIN);\n  var main = new OutputNode(head, mainName, MAIN, outputNodeRefCounts);\n  outputNodes[mainName] = main;\n  head = main;\n\n  if (isUnitModel(model)) {\n    materializeSelections(model, main);\n  } // add facet marker\n\n\n  var facetRoot = null;\n\n  if (isFacetModel(model)) {\n    var facetName = model.getName('facet'); // Derive new sort index field for facet's sort array\n\n    head = CalculateNode.parseAllForSortIndex(head, model); // Derive new aggregate for facet's sort field\n    // augment data source with new fields for crossed facet\n\n    head = (_l = makeJoinAggregateFromFacet(head, model.facet), _l !== null && _l !== void 0 ? _l : head);\n    facetRoot = new FacetNode(head, model, facetName, main.getSource());\n    outputNodes[facetName] = facetRoot;\n    head = facetRoot;\n  }\n\n  return Object.assign(Object.assign({}, model.component.data), {\n    outputNodes: outputNodes,\n    outputNodeRefCounts: outputNodeRefCounts,\n    raw: raw,\n    main: main,\n    facetRoot: facetRoot,\n    ancestorParse: ancestorParse\n  });\n}","map":null,"metadata":{},"sourceType":"module"}