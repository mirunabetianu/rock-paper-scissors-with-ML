{"ast":null,"code":"\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nvar _defineProperty = require(\"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/helpers/defineProperty\");\n\nvar _regeneratorRuntime = require(\"/Users/mirunabetianu/WebstormProjects/rps/node_modules/@babel/runtime/regenerator\");\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar linechart_1 = require(\"../render/linechart\");\n\nvar render_utils_1 = require(\"../render/render_utils\");\n\nvar dom_1 = require(\"../util/dom\");\n/**\n * Renders a tf.Model training 'History'.\n *\n * ```js\n * const model = tf.sequential({\n *  layers: [\n *    tf.layers.dense({inputShape: [784], units: 32, activation: 'relu'}),\n *    tf.layers.dense({units: 10, activation: 'softmax'}),\n *  ]\n * });\n *\n * model.compile({\n *   optimizer: 'sgd',\n *   loss: 'categoricalCrossentropy',\n *   metrics: ['accuracy']\n * });\n *\n * const data = tf.randomNormal([100, 784]);\n * const labels = tf.randomUniform([100, 10]);\n *\n * function onBatchEnd(batch, logs) {\n *   console.log('Accuracy', logs.acc);\n * }\n *\n * const surface = { name: 'show.history', tab: 'Training' };\n * // Train for 5 epochs with batch size of 32.\n * const history = await model.fit(data, labels, {\n *    epochs: 5,\n *    batchSize: 32\n * });\n *\n * tfvis.show.history(surface, history, ['loss', 'acc']);\n * ```\n *\n * ```js\n * const model = tf.sequential({\n *  layers: [\n *    tf.layers.dense({inputShape: [784], units: 32, activation: 'relu'}),\n *    tf.layers.dense({units: 10, activation: 'softmax'}),\n *  ]\n * });\n *\n * model.compile({\n *   optimizer: 'sgd',\n *   loss: 'categoricalCrossentropy',\n *   metrics: ['accuracy']\n * });\n *\n * const data = tf.randomNormal([100, 784]);\n * const labels = tf.randomUniform([100, 10]);\n *\n * function onBatchEnd(batch, logs) {\n *   console.log('Accuracy', logs.acc);\n * }\n *\n * const surface = { name: 'show.history live', tab: 'Training' };\n * // Train for 5 epochs with batch size of 32.\n * const history = [];\n * await model.fit(data, labels, {\n *    epochs: 5,\n *    batchSize: 32,\n *    callbacks: {\n *      onEpochEnd: (epoch, log) => {\n *        history.push(log);\n *        tfvis.show.history(surface, history, ['loss', 'acc']);\n *      }\n *    }\n * });\n * ```\n *\n * @param history A history like object. Either a tfjs-layers `History` object\n *  or an array of tfjs-layers `Logs` objects.\n * @param metrics An array of strings for each metric to plot from the history\n *  object. Using this allows you to control which metrics appear on the same\n *  plot.\n * @param opts Optional parameters for the line charts.\n */\n\n/**\n * @doc {heading: 'Models & Tensors', subheading: 'Model Training', namespace:\n * 'show'}\n */\n\n\nfunction history(container, history, metrics) {\n  var opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  return __awaiter(this, void 0, void 0,\n  /*#__PURE__*/\n  _regeneratorRuntime.mark(function _callee() {\n    var drawArea, plots, _iteratorNormalCompletion, _didIteratorError, _iteratorError, _iterator, _step, metric, values, nonValidationMetric, _values, plotNames, options, renderPromises, _i, _plotNames, name, subContainer, series, _values2, done;\n\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            // Get the draw surface\n            drawArea = render_utils_1.getDrawArea(container); // We organize the data from the history object into discrete plot data\n            // objects so that we can group together appropriate metrics into single\n            // multi-series charts.\n\n            plots = {};\n            _iteratorNormalCompletion = true;\n            _didIteratorError = false;\n            _iteratorError = undefined;\n            _context.prev = 5;\n\n            for (_iterator = metrics[Symbol.iterator](); !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n              metric = _step.value;\n\n              if (!/val_/.test(metric)) {\n                // Non validation metric\n                values = getValues(history, metric, metrics.indexOf(metric));\n                initPlot(plots, metric);\n                plots[metric].series.push(metric);\n                plots[metric].values.push(values);\n              } else {\n                // Validation metrics are grouped with their equivalent non validation\n                // metrics. Note that the corresponding non validation metric may not\n                // actually be included but we still want to use it as a plot name.\n                nonValidationMetric = metric.replace('val_', '');\n                initPlot(plots, nonValidationMetric);\n                _values = getValues(history, metric, metrics.indexOf(metric));\n                plots[nonValidationMetric].series.push(metric);\n                plots[nonValidationMetric].values.push(_values);\n              }\n            } // Render each plot specified above to a new subsurface.\n            // A plot may have multiple series.\n\n\n            _context.next = 13;\n            break;\n\n          case 9:\n            _context.prev = 9;\n            _context.t0 = _context[\"catch\"](5);\n            _didIteratorError = true;\n            _iteratorError = _context.t0;\n\n          case 13:\n            _context.prev = 13;\n            _context.prev = 14;\n\n            if (!_iteratorNormalCompletion && _iterator.return != null) {\n              _iterator.return();\n            }\n\n          case 16:\n            _context.prev = 16;\n\n            if (!_didIteratorError) {\n              _context.next = 19;\n              break;\n            }\n\n            throw _iteratorError;\n\n          case 19:\n            return _context.finish(16);\n\n          case 20:\n            return _context.finish(13);\n\n          case 21:\n            plotNames = Object.keys(plots);\n            options = Object.assign({}, {\n              xLabel: 'Iteration',\n              yLabel: 'Value'\n            }, opts);\n            renderPromises = [];\n\n            for (_i = 0, _plotNames = plotNames; _i < _plotNames.length; _i++) {\n              name = _plotNames[_i];\n              subContainer = dom_1.subSurface(drawArea, name);\n              series = plots[name].series;\n              _values2 = plots[name].values;\n\n              if (series.every(function (seriesName) {\n                return Boolean(seriesName.match('acc'));\n              })) {\n                // Set a domain of 0-1 if all the series in this plot are related to\n                // accuracy. Can be overridden by setting zoomToFitAccuracy to true.\n                if (options.zoomToFitAccuracy) {\n                  options.zoomToFit = true;\n                } else {\n                  options.yAxisDomain = [0, 1];\n                  delete options.zoomToFit;\n                }\n              }\n\n              done = linechart_1.linechart(subContainer, {\n                values: _values2,\n                series: series\n              }, options);\n              renderPromises.push(done);\n            }\n\n            _context.next = 27;\n            return Promise.all(renderPromises);\n\n          case 27:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, null, [[5, 9, 13, 21], [14,, 16, 20]]);\n  }));\n}\n\nexports.history = history;\n\nfunction initPlot(plot, name) {\n  if (plot[name] == null) {\n    plot[name] = {\n      series: [],\n      values: []\n    };\n  }\n}\n/*\n * Extracts a list of Point2D's suitable for plotting from a HistoryLike for\n * a single metric.\n * @param history a HistoryLike object\n * @param metric the metric to extract from the logs\n * @param metricIndex this is needed because the historylike can be a nested\n * list of logs for multiple metrics, this index lets us extract the correct\n * list.\n */\n\n\nfunction getValues(history, metric, metricIndex) {\n  if (Array.isArray(history)) {\n    // If we were passed a nested array we want to get the correct list\n    // for this given metric, metrix index gives us this list.\n    var metricHistory = Array.isArray(history[0]) ? history[metricIndex] : history;\n    var points = [];\n\n    for (var i = 0; i < metricHistory.length; i++) {\n      var log = metricHistory[i];\n      points.push({\n        x: i,\n        y: log[metric]\n      });\n    }\n\n    return points;\n  } else {\n    return history.history[metric].map(function (y, x) {\n      return {\n        x: x,\n        y: y\n      };\n    });\n  }\n}\n/**\n * Returns a collection of callbacks to pass to tf.Model.fit. Callbacks are\n * returned for the following events, `onBatchEnd` & `onEpochEnd`.\n *\n * ```js\n * const model = tf.sequential({\n *  layers: [\n *    tf.layers.dense({inputShape: [784], units: 32, activation: 'relu'}),\n *    tf.layers.dense({units: 10, activation: 'softmax'}),\n *  ]\n * });\n *\n * model.compile({\n *   optimizer: 'sgd',\n *   loss: 'categoricalCrossentropy',\n *   metrics: ['accuracy']\n * });\n *\n * const data = tf.randomNormal([100, 784]);\n * const labels = tf.randomUniform([100, 10]);\n *\n * function onBatchEnd(batch, logs) {\n *   console.log('Accuracy', logs.acc);\n * }\n *\n * const surface = { name: 'show.fitCallbacks', tab: 'Training' };\n * // Train for 5 epochs with batch size of 32.\n * await model.fit(data, labels, {\n *    epochs: 5,\n *    batchSize: 32,\n *    callbacks: tfvis.show.fitCallbacks(surface, ['loss', 'acc']),\n * });\n * ```\n *\n * @param metrics List of metrics to plot.\n * @param opts Optional parameters\n */\n\n/**\n * @doc {heading: 'Models & Tensors', subheading: 'Model Training', namespace:\n * 'show'}\n */\n\n\nfunction fitCallbacks(container, metrics) {\n  var opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  var accumulators = {};\n  var callbackNames = opts.callbacks || ['onEpochEnd', 'onBatchEnd'];\n  var drawArea = render_utils_1.getDrawArea(container);\n  var historyOpts = Object.assign({}, opts);\n  delete historyOpts.callbacks;\n\n  function makeCallbackFor(callbackName) {\n    var _this = this;\n\n    return function (_, log) {\n      return __awaiter(_this, void 0, void 0,\n      /*#__PURE__*/\n      _regeneratorRuntime.mark(function _callee2() {\n        var metricLogs, presentMetrics, _iteratorNormalCompletion2, _didIteratorError2, _iteratorError2, _iterator2, _step2, metric, accumulator, subContainer;\n\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                // Set a nicer x axis name where possible\n                if (/batch/i.test(callbackName)) {\n                  historyOpts.xLabel = 'Batch';\n                } else if (/epoch/i.test(callbackName)) {\n                  historyOpts.xLabel = 'Epoch';\n                } // Because of how the _ (iteration) numbers are given in the layers api\n                // we have to store each metric for each callback in different arrays else\n                // we cannot get accurate 'global' batch numbers for onBatchEnd.\n                // However at render time we want to be able to combine metrics for a\n                // given callback. So here we make a nested list of metrics, the first\n                // level are arrays for each callback, the second level contains arrays\n                // (of logs) for each metric within that callback.\n\n\n                metricLogs = [];\n                presentMetrics = [];\n                _iteratorNormalCompletion2 = true;\n                _didIteratorError2 = false;\n                _iteratorError2 = undefined;\n                _context2.prev = 6;\n\n                for (_iterator2 = metrics[Symbol.iterator](); !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {\n                  metric = _step2.value;\n\n                  // not all logs have all kinds of metrics.\n                  if (log[metric] != null) {\n                    presentMetrics.push(metric);\n                    accumulator = getAccumulator(accumulators, callbackName, metric);\n                    accumulator.push(_defineProperty({}, metric, log[metric]));\n                    metricLogs.push(accumulator);\n                  }\n                }\n\n                _context2.next = 14;\n                break;\n\n              case 10:\n                _context2.prev = 10;\n                _context2.t0 = _context2[\"catch\"](6);\n                _didIteratorError2 = true;\n                _iteratorError2 = _context2.t0;\n\n              case 14:\n                _context2.prev = 14;\n                _context2.prev = 15;\n\n                if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n                  _iterator2.return();\n                }\n\n              case 17:\n                _context2.prev = 17;\n\n                if (!_didIteratorError2) {\n                  _context2.next = 20;\n                  break;\n                }\n\n                throw _iteratorError2;\n\n              case 20:\n                return _context2.finish(17);\n\n              case 21:\n                return _context2.finish(14);\n\n              case 22:\n                subContainer = dom_1.subSurface(drawArea, callbackName, {\n                  title: callbackName\n                });\n                history(subContainer, metricLogs, presentMetrics, historyOpts);\n                _context2.next = 26;\n                return render_utils_1.nextFrame();\n\n              case 26:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, null, [[6, 10, 14, 22], [15,, 17, 21]]);\n      }));\n    };\n  }\n\n  var callbacks = {};\n  callbackNames.forEach(function (name) {\n    callbacks[name] = makeCallbackFor(name);\n  });\n  return callbacks;\n}\n\nexports.fitCallbacks = fitCallbacks;\n\nfunction getAccumulator(accumulators, callback, metric) {\n  if (accumulators[callback] == null) {\n    accumulators[callback] = {};\n  }\n\n  if (accumulators[callback][metric] == null) {\n    accumulators[callback][metric] = [];\n  }\n\n  return accumulators[callback][metric];\n}","map":null,"metadata":{},"sourceType":"script"}